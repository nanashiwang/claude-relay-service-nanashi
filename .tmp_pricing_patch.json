{
    "value":  [
                  {
                      "op":  "add",
                      "path":  "/gpt-5.3",
                      "value":  {
                                    "cache_read_input_token_cost":  1.25E-07,
                                    "cache_read_input_token_cost_flex":  6.25E-08,
                                    "cache_read_input_token_cost_priority":  2.5E-07,
                                    "input_cost_per_token":  1.25E-06,
                                    "input_cost_per_token_flex":  6.25E-07,
                                    "input_cost_per_token_priority":  2.5E-06,
                                    "litellm_provider":  "openai",
                                    "max_input_tokens":  272000,
                                    "max_output_tokens":  128000,
                                    "max_tokens":  128000,
                                    "mode":  "chat",
                                    "output_cost_per_token":  1E-05,
                                    "output_cost_per_token_flex":  5E-06,
                                    "output_cost_per_token_priority":  2E-05,
                                    "supported_endpoints":  [
                                                                "/v1/chat/completions",
                                                                "/v1/batch",
                                                                "/v1/responses"
                                                            ],
                                    "supported_modalities":  [
                                                                 "text",
                                                                 "image"
                                                             ],
                                    "supported_output_modalities":  [
                                                                        "text"
                                                                    ],
                                    "supports_function_calling":  true,
                                    "supports_native_streaming":  true,
                                    "supports_parallel_function_calling":  true,
                                    "supports_pdf_input":  true,
                                    "supports_prompt_caching":  true,
                                    "supports_reasoning":  true,
                                    "supports_response_schema":  true,
                                    "supports_system_messages":  true,
                                    "supports_tool_choice":  true,
                                    "supports_vision":  true
                                }
                  },
                  {
                      "op":  "add",
                      "path":  "/gpt-5.3-codex",
                      "value":  {
                                    "cache_read_input_token_cost":  1.25E-07,
                                    "cache_read_input_token_cost_flex":  6.25E-08,
                                    "cache_read_input_token_cost_priority":  2.5E-07,
                                    "input_cost_per_token":  1.25E-06,
                                    "input_cost_per_token_flex":  6.25E-07,
                                    "input_cost_per_token_priority":  2.5E-06,
                                    "litellm_provider":  "openai",
                                    "max_input_tokens":  272000,
                                    "max_output_tokens":  128000,
                                    "max_tokens":  128000,
                                    "mode":  "chat",
                                    "output_cost_per_token":  1E-05,
                                    "output_cost_per_token_flex":  5E-06,
                                    "output_cost_per_token_priority":  2E-05,
                                    "supported_endpoints":  [
                                                                "/v1/chat/completions",
                                                                "/v1/batch",
                                                                "/v1/responses"
                                                            ],
                                    "supported_modalities":  [
                                                                 "text",
                                                                 "image"
                                                             ],
                                    "supported_output_modalities":  [
                                                                        "text"
                                                                    ],
                                    "supports_function_calling":  true,
                                    "supports_native_streaming":  true,
                                    "supports_parallel_function_calling":  true,
                                    "supports_pdf_input":  true,
                                    "supports_prompt_caching":  true,
                                    "supports_reasoning":  true,
                                    "supports_response_schema":  true,
                                    "supports_system_messages":  true,
                                    "supports_tool_choice":  true,
                                    "supports_vision":  true
                                }
                  }
              ],
    "Count":  2
}
